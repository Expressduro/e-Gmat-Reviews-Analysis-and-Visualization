# -*- coding: utf-8 -*-
"""e-Gmat Scrapping and Visualizations.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nIbmXUjio2lLITkU8zpG_UrzpjQakZ7e
"""

import pandas as pd

df = pd.read_csv(
    "/content/drive/MyDrive/gmatclub.csv",
    quotechar='"',
    encoding='utf-8',
    on_bad_lines='skip'  # skips lines with too many/few fields
)

df.columns = df.columns.str.strip()  # clean whitespace

df = df.dropna(subset=["coursesReviews-review_body-content"])
df.rename(columns={"coursesReviews-review_body-content": "review"}, inplace=True)
df.reset_index(drop=True, inplace=True)
df.head(3)

import openai
from openai import OpenAI
import pandas as pd
from tqdm import tqdm

review_col = 'review' if 'review' in df.columns else df.columns[0]  # fallback
reviews = df[review_col].dropna().tolist()

# Sample 300 reviews for GPT processing (due to token limit)
sampled_reviews = reviews[:1001]

# Set your GPT API key
client = OpenAI(api_key="your api key")  # replace with your actual key

# Collect feature request prompts
feature_requests = []

print("Extracting feature requests from sampled reviews...")

for review in tqdm(sampled_reviews):
    prompt = f"""
    The following is a student review of the e-GMAT course. Extract any specific feature requests or product improvements the student mentions (if any). Return a short, clear list. If none, return 'None'.

    Review: {review}
    """
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "user", "content": prompt}
        ],
        temperature=0.3
    )
    output = response.choices[0].message.content.strip()
    if output.lower() != "none":
        feature_requests.append(output)

# Save feature requests to a file
with open("feature_requests.txt", "w") as f:
    for req in feature_requests:
        f.write(req + "\n")

# Read the saved feature requests
with open("feature_requests.txt", "r") as f:
    feature_requests = [line.strip() for line in f if line.strip().lower() != "none"]

def chunk_list(lst, chunk_size):
    for i in range(0, len(lst), chunk_size):
        yield lst[i:i + chunk_size]

feature_chunks = list(chunk_list(feature_requests, 200))

from openai import OpenAI
from tqdm import tqdm

client = OpenAI(api_key="your api key")

all_summaries = []

print("Analyzing feature requests in GPT for clustering...")

for i, chunk in enumerate(tqdm(feature_chunks)):
    combined_features = "\n".join(chunk)

    prompt = f"""
    The following is a list of feature requests collected from student reviews of e-GMAT. Your task is to identify and summarize the top 3-5 most frequently mentioned themes or product requests. Group similar ones together under a clear title, and for each group, provide a short description of what users want. List them in order of frequency based on your judgment.

    Feature Requests:
    {combined_features}
    """

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )

    summary = response.choices[0].message.content.strip()
    all_summaries.append(summary)

print(all_summaries)

final_prompt = f"""
You are given several GPT summaries of grouped feature requests from 1000 student reviews of e-GMAT. Your task is to merge and deduplicate them into one list of the **top 5 most requested features**.

Each entry should include:
- The name of the feature group
- A 2-line description of what users want
- Why it's important to them

Summaries:
{''.join(all_summaries)}
"""

response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": final_prompt}],
    temperature=0.3
)

final_feature_list = response.choices[0].message.content.strip()
print(final_feature_list)

from openai import OpenAI
from tqdm import tqdm
import json

# Initialize OpenAI client
client = OpenAI(api_key="your api key")  # replace with your key

# Load your 1000 reviews (or however many)
with open("feature_requests.txt", "r") as f:
    all_reviews = [line.strip() for line in f if line.strip()]

# Define the 5 feature categories
categories = {
    "1. Improve Course Content and Structure": [],
    "2. Enhance Question Quality and Variety": [],
    "3. Improve Mock Tests and Practice Materials": [],
    "4. Enhance User Interface and Functionality": [],
    "5. Provide More Support and Resources": []
}

# Prompt template
prompt_template = """
The following is a student review of the e-GMAT course:

"{review}"

Identify which of the following feature improvement categories this review supports. List all that apply.

1. Improve Course Content and Structure
2. Enhance Question Quality and Variety
3. Improve Mock Tests and Practice Materials
4. Enhance User Interface and Functionality
5. Provide More Support and Resources

Respond with only the numbers of the applicable categories, separated by commas (e.g., "1, 3, 5"). If none apply, return "None".
"""

# Start review classification
print("Classifying reviews by feature improvement area...\n")

for review in tqdm(all_reviews):
    prompt = prompt_template.format(review=review)
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )
        output = response.choices[0].message.content.strip()

        if output.lower() == "none":
            continue

        selected_nums = [num.strip() for num in output.split(",")]
        for num in selected_nums:
            if num in categories:
                categories[num].append(review)
            elif num.isdigit() and f"{num}. " in " ".join(categories.keys()):
                matched_key = next(k for k in categories if k.startswith(f"{num}. "))
                categories[matched_key].append(review)
    except Exception as e:
        print(f"Error on review: {review}\n{e}\n")

# Save the results
for feature, reviews in categories.items():
    filename = f"feature_{feature.split('.')[0]}_reviews.txt"
    with open(filename, "w") as f:
        for r in reviews:
            f.write(r + "\n")

# Summary
print("\n--- Summary of Results ---")
for k, v in categories.items():
    print(f"{k}: {len(v)} reviews")

from openai import OpenAI
from tqdm import tqdm
import json
from collections import defaultdict

# Initialize OpenAI client
client = OpenAI(api_key="your api key")

# Load reviews (assumes recent reviews)
with open("feature_requests.txt", "r") as f:
    recent_reviews = [line.strip() for line in f if line.strip()]

# Categories to count praises
praise_counts = defaultdict(int)
praise_examples = defaultdict(list)

# Prompt template to extract praises
prompt_template = """
You are an analyst reviewing student feedback on the e-GMAT platform.

Here is one student review:
"{review}"

Your task is to extract what specific features/aspects the student is praising.
Return a short list of the praised aspects (e.g., course content, mock tests, instructors, UI, etc.).
If the review contains no praise, return "None".

Respond in this format ONLY:
Praise: <comma-separated list or 'None'>
"""

print("Extracting praised features from recent reviews...\n")

for review in tqdm(recent_reviews):
    prompt = prompt_template.format(review=review)

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )
        output = response.choices[0].message.content.strip()

        if "Praise:" not in output:
            continue

        praised_line = output.split("Praise:")[-1].strip()
        if praised_line.lower() == "none":
            continue

        praised_items = [item.strip().lower() for item in praised_line.split(",")]
        for item in praised_items:
            if item:
                praise_counts[item] += 1
                if len(praise_examples[item]) < 5:  # Store only top 5 examples per category
                    praise_examples[item].append(review)

    except Exception as e:
        print(f"Error with review: {review}\n{e}\n")

# Save counts and examples to file
with open("praise_counts.json", "w") as f:
    json.dump(praise_counts, f, indent=2)

with open("praise_examples.json", "w") as f:
    json.dump(praise_examples, f, indent=2)

# Print summary
print("\n--- Top Praised Features (with example counts) ---")
sorted_praises = sorted(praise_counts.items(), key=lambda x: x[1], reverse=True)
for feature, count in sorted_praises:
    print(f"{feature.title()}: {count} praises")

import pandas as pd
from openai import OpenAI
from tqdm import tqdm
from collections import defaultdict
import matplotlib.pyplot as plt
import os



# Load reviews
df = pd.read_csv("/content/drive/MyDrive/gmatclub.csv")
df = df.rename(columns=lambda x: x.strip().lower().replace(" ", "_"))
df = df.rename(columns={"coursesreviews-review_body-content": "review", "posting-date": "date"})

# Extract year
df["year"] = pd.to_datetime(df["date"], errors="coerce").dt.year
df = df.dropna(subset=["review", "year"])

# Prepare prompt
feature_prompt_template = """
The following is a review from a student about the e-GMAT course:

"{review}"

Which of the following key aspects are praised or mentioned in the review? List all that apply.

1. Course Content
2. Question Quality
3. Mock Tests
4. User Interface / Experience
5. Support and Resources

Respond with the numbers of the applicable categories only, like "1, 2". If none apply, respond with "None".
"""

# Dictionary to store results
year_feature_counts = defaultdict(lambda: defaultdict(int))

# GPT-based tagging
print("Classifying reviews using GPT...\n")

for _, row in tqdm(df.iterrows(), total=len(df)):
    review = row["review"]
    year = int(row["year"])

    prompt = feature_prompt_template.format(review=review.strip()[:1500])  # Trim for token safety

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        output = response.choices[0].message.content.strip()

        if output.lower() == "none":
            continue

        selected = [s.strip() for s in output.split(",") if s.strip().isdigit()]
        for num in selected:
            feature_map = {
                "1": "Course Content",
                "2": "Question Quality",
                "3": "Mock Tests",
                "4": "User Interface",
                "5": "Support and Resources"
            }
            if num in feature_map:
                year_feature_counts[year][feature_map[num]] += 1

    except Exception as e:
        print(f"Error classifying review: {review[:100]}\n{e}")

# Convert to DataFrame
summary_df = pd.DataFrame(year_feature_counts).T.fillna(0).astype(int).sort_index()

# Plotting
plt.figure(figsize=(12, 6))
for feature in summary_df.columns:
    plt.plot(summary_df.index, summary_df[feature], marker='o', label=feature)

plt.title("Evolution of Key Features in e-GMAT Reviews (GPT-based Analysis)")
plt.xlabel("Year")
plt.ylabel("Mentions")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("gpt_feature_trend.png")
plt.show()

# Summary
print("\n===== Feature Trend Summary =====")
for feature in summary_df.columns:
    trend = "increasing" if summary_df[feature].iloc[-1] > summary_df[feature].iloc[0] else \
            "decreasing" if summary_df[feature].iloc[-1] < summary_df[feature].iloc[0] else "stable"
    print(f"{feature}: {trend} trend (from {summary_df[feature].iloc[0]} in {summary_df.index[0]} to {summary_df[feature].iloc[-1]} in {summary_df.index[-1]})")

